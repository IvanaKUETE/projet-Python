{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"border: thick double #32a1ce; text-align:center;border-radius:35px\">\n",
    "Modélisation statistiques\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies standards\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work directory: /home/onyxia/work/projet-Python/projet \n",
      "Data directory: /home/onyxia/work/projet-Python/projet/notebook\n"
     ]
    }
   ],
   "source": [
    "# Définition du répertoire de travail\n",
    "HOME_DIR = Path.cwd().parent\n",
    "DATA_DIR = Path(HOME_DIR, \"notebook\")\n",
    "print(f\"Work directory: {HOME_DIR} \\nData directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Principal_data4 = pd.read_csv(Path(DATA_DIR, \"Principal_data4.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"border: thick double #32a1ce; text-align:center;border-radius:35px\">\n",
    "I- feature scaling des variables\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables de notre jeu de données ayant une très grande échelle, nous allons faire du feature scaling (les remettre à l'echelle) pour rendre nos données homogènes. La méthode privilégiée dans notre cas est la standardisation car les méthodes (regression logistique ) utilisées reposent sur l'hypothèse de normalité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cla_age_5', 'sexe', 'dept', 'prev', 'Niveau prioritaire', 'no2', 'o3',\n",
       "       'pm10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Principal_data4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sexe', 'dept', 'prev', 'no2', 'o3', 'pm10'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_num = Principal_data4.select_dtypes(['int64','float64']).columns\n",
    "col_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cla_age_5', 'Niveau prioritaire'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Var_cat=Principal_data4.select_dtypes(['object']).columns\n",
    "Var_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_norm=[ 'sexe', 'dept', 'prev', 'no2', 'o3', 'pm10']\n",
    "var_cat=['cla_age_5', 'Niveau prioritaire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sexe    0\n",
       "dept    0\n",
       "prev    0\n",
       "no2     0\n",
       "o3      0\n",
       "pm10    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Principal_data4[var_norm].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1352 entries, 0 to 1351\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   cla_age_5           1352 non-null   object \n",
      " 1   sexe                1352 non-null   int64  \n",
      " 2   dept                1352 non-null   int64  \n",
      " 3   prev                1352 non-null   float64\n",
      " 4   Niveau prioritaire  1352 non-null   object \n",
      " 5   no2                 1352 non-null   float64\n",
      " 6   o3                  1352 non-null   float64\n",
      " 7   pm10                1352 non-null   float64\n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 84.6+ KB\n"
     ]
    }
   ],
   "source": [
    "Principal_data4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style= \"text-align:left\">\n",
    "I.1- Standardisation  des variables numériques \n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style= \"text-align:left\">\n",
    "I.1.a-  Standarscaler \n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardisation des variables numériques\n",
    "Principal_data4[var_norm] = StandardScaler().fit_transform(Principal_data4[var_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiaction de la normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verification_normalisation(data_mod):\n",
    "      for variable_norm in data_mod :\n",
    "        data_mod_col=data_mod[variable_norm]\n",
    "        moyenne=np.mean(data_mod_col)\n",
    "        ecartType = np.std(data_mod_col)\n",
    "\n",
    "        print(\"les statistiques pour la variable {}\" .format(variable_norm))\n",
    "        print(\"La moyenne est de : {} \".format(round(abs(moyenne), 2)))\n",
    "        print(\"L'écart type est de : {} \".format(round(abs(ecartType), 2)))\n",
    "        print(\" \")\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les statistiques pour la variable sexe\n",
      "La moyenne est de : 0.0 \n",
      "L'écart type est de : 1.0 \n",
      " \n",
      " \n",
      "les statistiques pour la variable dept\n",
      "La moyenne est de : 0.0 \n",
      "L'écart type est de : 1.0 \n",
      " \n",
      " \n",
      "les statistiques pour la variable prev\n",
      "La moyenne est de : 0.0 \n",
      "L'écart type est de : 1.0 \n",
      " \n",
      " \n",
      "les statistiques pour la variable no2\n",
      "La moyenne est de : 0.0 \n",
      "L'écart type est de : 1.0 \n",
      " \n",
      " \n",
      "les statistiques pour la variable o3\n",
      "La moyenne est de : 0.0 \n",
      "L'écart type est de : 1.0 \n",
      " \n",
      " \n",
      "les statistiques pour la variable pm10\n",
      "La moyenne est de : 0.0 \n",
      "L'écart type est de : 1.0 \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "verification_normalisation(Principal_data4[var_norm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style= \"text-align:left\">\n",
    "I.2- Encodage des variables catégorielles \n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage binaire sexe\n",
    "Principal_data4[\"sexe\"] = Principal_data4[\"sexe\"].map({1: 1, 2: 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes à encoder en One-Hot\n",
    "onehot_features = [\"dept\", \"cla_age_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes à encoder en One-Hot\n",
    "onehot_features = [\"dept\", \"cla_age_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes à laisser en l'état (numériques ou déjà transformées)\n",
    "# Ex: \"prev\", \"no2\", \"pm10\", \"o3\", \"sexe\", \"Niveau prioritaire\", etc.\n",
    "# Remainder='passthrough' va les conserver sans transformation\n",
    "# Définition du ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ohe\", OneHotEncoder(drop=\"first\", sparse_output = False) , onehot_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Application du ColumnTransformer (ou dans un Pipeline)\n",
    "\n",
    "df_array = preprocessor.fit_transform(Principal_data4)\n",
    "\n",
    "# Récupération des noms des colonnes One-Hot\n",
    "onehot_colnames = preprocessor.named_transformers_[\"ohe\"].get_feature_names_out(onehot_features)\n",
    "# Récupération des noms de colonnes \"passthrough\" dans l'ordre\n",
    "passthrough_cols = [col for col in Principal_data4.columns if col not in onehot_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept_-1.2133166377093498</th>\n",
       "      <th>dept_-1.089194051890415</th>\n",
       "      <th>dept_0.524399563755735</th>\n",
       "      <th>dept_0.6485221495746697</th>\n",
       "      <th>dept_0.7726447353936043</th>\n",
       "      <th>dept_0.896767321212539</th>\n",
       "      <th>dept_1.0208899070314736</th>\n",
       "      <th>cla_age_5_05-09</th>\n",
       "      <th>cla_age_5_10-14</th>\n",
       "      <th>cla_age_5_15-19</th>\n",
       "      <th>...</th>\n",
       "      <th>cla_age_5_85-89</th>\n",
       "      <th>cla_age_5_90-94</th>\n",
       "      <th>cla_age_5_95et+</th>\n",
       "      <th>cla_age_5_tsage</th>\n",
       "      <th>sexe</th>\n",
       "      <th>prev</th>\n",
       "      <th>Niveau prioritaire</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>pm10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.660927</td>\n",
       "      <td>1,2,3</td>\n",
       "      <td>-0.649703</td>\n",
       "      <td>1.103346</td>\n",
       "      <td>0.003698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.303524</td>\n",
       "      <td>1,2,3</td>\n",
       "      <td>-1.130356</td>\n",
       "      <td>0.706744</td>\n",
       "      <td>-1.623907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dept_-1.2133166377093498 dept_-1.089194051890415 dept_0.524399563755735  \\\n",
       "0                      1.0                     0.0                    0.0   \n",
       "1                      0.0                     0.0                    1.0   \n",
       "\n",
       "  dept_0.6485221495746697 dept_0.7726447353936043 dept_0.896767321212539  \\\n",
       "0                     0.0                     0.0                    0.0   \n",
       "1                     0.0                     0.0                    0.0   \n",
       "\n",
       "  dept_1.0208899070314736 cla_age_5_05-09 cla_age_5_10-14 cla_age_5_15-19  \\\n",
       "0                     0.0             0.0             0.0             0.0   \n",
       "1                     0.0             0.0             0.0             0.0   \n",
       "\n",
       "   ... cla_age_5_85-89 cla_age_5_90-94 cla_age_5_95et+ cla_age_5_tsage sexe  \\\n",
       "0  ...             1.0             0.0             0.0             0.0  NaN   \n",
       "1  ...             1.0             0.0             0.0             0.0  NaN   \n",
       "\n",
       "       prev Niveau prioritaire       no2        o3      pm10  \n",
       "0  2.660927              1,2,3 -0.649703  1.103346  0.003698  \n",
       "1  2.303524              1,2,3 -1.130356  0.706744 -1.623907  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fusion des noms dans le bon ordre\n",
    "final_col_names = list(onehot_colnames) + passthrough_cols\n",
    "\n",
    "# Création d'un nouveau DataFrame final\n",
    "df_final = pd.DataFrame(df_array, columns=final_col_names)\n",
    "\n",
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style= \"text-align:left\">\n",
    "Recherche du meilleur algorithme \n",
    "</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
